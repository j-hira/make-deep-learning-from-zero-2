{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        # 学習すべきパラメータ\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W, b]\n",
    "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        W, b = self.params\n",
    "        out = x @ W + b\n",
    "        self.x = x\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        W, b = self.params\n",
    "        dx = dout @ W.T\n",
    "        dW = self.x.T @ dout\n",
    "        db = np.sum(dout, axis=0)\n",
    "        \n",
    "        self.grads[0][...] = dW\n",
    "        self.grads[1][...] = db\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        I, H, O = input_size, hidden_size, output_size\n",
    "        # np.random.randn(N, M) -> N x M行列を平均0,分散1の要素で初期化\n",
    "        W1 = np.random.randn(I, H)\n",
    "        b1 = np.random.randn(H)\n",
    "        W2 = np.random.randn(H, O)\n",
    "        b2 = np.random.randn(O)\n",
    "\n",
    "        # レイヤを生成\n",
    "        self.layers = [\n",
    "            Affine(W1, b1),\n",
    "            Sigmoid(),\n",
    "            Affine(W2, b2)\n",
    "        ]\n",
    "\n",
    "        self.params = []\n",
    "        for layer in self.layers:\n",
    "            # [\"a\"] + [\"b\"] = [\"a\", \"b\"]\n",
    "            self.params += layer.params\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23619298,  0.00229068,  0.65030179],\n",
       "       [-0.05293865, -0.02328527,  0.57617352],\n",
       "       [ 0.48715121, -0.24834236,  1.53056043],\n",
       "       [ 0.04047487, -0.17391956,  1.07177243],\n",
       "       [ 0.13119861, -0.06401978,  0.80785507],\n",
       "       [ 0.52827798, -0.13322359,  1.14920659],\n",
       "       [ 0.17397363,  0.14425726,  0.19802903],\n",
       "       [-0.12506433,  0.17143604, -0.0159623 ],\n",
       "       [ 0.1312029 ,  0.44498955, -0.4201796 ],\n",
       "       [ 0.41918093,  0.26032664,  0.10244893]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randn(10, 2)\n",
    "model = TwoLayerNet(2, 4, 3)\n",
    "s = model.predict(x)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# この層自体に入力は複数ある\n",
    "# 入力の次元と出力の次元は同じ\n",
    "# 入力一つ一つに対しての確率を出力する\n",
    "def softmax(x):\n",
    "    # 入力が行列のとき\n",
    "    if x.ndim == 2:\n",
    "        # axisで軸の方向を決める\n",
    "        # 0の場合は行ごと,1の場合は列ごとの最大値を求める\n",
    "        # keepdimsをTrueにすることで二次配列のままになる\n",
    "        x = x - x.max(axis=1, keepdims=True)\n",
    "        x = np.exp(x)\n",
    "        x = x / x.sum(axis=1, keepdims=True)\n",
    "    # 入力がベクトルのとき\n",
    "    elif x.ndim == 1:\n",
    "        x = x - np.max(x) # ここはオーバーフロー対策のためであって,理論的にはこの行は必要ない.ただしこの行があっても確率が変わらない?\n",
    "        x = np.exp(x) / np.sum(np.exp(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        # 二次配列に変更\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    # 教師データがone-hot-vectorの場合sizeが同じになる\n",
    "    # 正解ラベルのインデックスのベクトルとなる\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "    # 行数を取得\n",
    "    batch_size = y.shape[0]\n",
    "\n",
    "    # np.arange(stop) 0 <= n < stop で間隔1でndarrayを生成\n",
    "    # + 1e-7 これにより,予測データが0のときにエラーになるのを防ぐ\n",
    "    # y[np.arange(batch_size), t] yが二次配列で\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.56090121,  1.57959197, -0.19413277,  0.44233324]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randn(1, 4)\n",
    "a = a.reshape(1, a.size)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! チェインルール\n",
    "class MatMul:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grabs = [np.zeros_like(W)]\n",
    "        self.x = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        W, = self.params\n",
    "        out = x @ W\n",
    "        self.x = x\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        W, = self.params\n",
    "        dx = dout @ W.T\n",
    "        dW = np.dot(self.x.T, dout)\n",
    "        # 最初の[0]はもともとリストのなかでnp.zeros_likeをしているため [...]でdeepcopyしている\n",
    "        self.grads[0][...] = dW\n",
    "        return dx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
